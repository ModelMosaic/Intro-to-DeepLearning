{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5d48a90-dab1-4424-a398-31ba152787a4",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568014f-d58f-4935-a8fe-e8bd0c02ecd6",
   "metadata": {},
   "source": [
    "1. Introduction to Object Detection\n",
    "- Object detection is a key technique in computer vision that involves identifying and locating objects within an image or video. - - It goes a step beyond image classification by not only categorizing the objects but also pinpointing their positions. \n",
    "- This technology has significant applications in various fields, from surveillance systems that can detect suspicious activities to autonomous vehicles that need to recognize obstacles. \n",
    "- For instance, in retail, object detection helps in automated checkout systems by recognizing products without the need for barcodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37ad36-92d7-41f0-ba29-85b2401e46e1",
   "metadata": {},
   "source": [
    "### 2. Key Components of Object Detection\n",
    "- Landmarks: Specific points within an object (like corners of the eyes or nose tip in face detection).\n",
    "- Anchors: Predetermined boxes of various scales and aspect ratios that serve as reference points.\n",
    "- Bounding Boxes: Rectangles that enclose objects, defined by coordinates (x, y, width, height).\n",
    "- Grids: The image is divided into a grid, and object detection is performed in each grid cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4249f0-0763-4b9a-b232-5bac57c78c45",
   "metadata": {},
   "source": [
    "### 3. Implementing Basic Object Detection\n",
    "- We'll start by implementing a simple object detection system using a pre-trained model from TensorFlow's model zoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82ebbc-1457-4eb3-aff3-a20f01045f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033b02e-b511-451e-a9c9-7060249fad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb518e1-343a-48d9-8801-6fda63c71048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the model from TensorFlow Hub\n",
    "model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_1024x1024/1\")\n",
    "\n",
    "# Function to run object detection\n",
    "def detect_objects(image_np, model):\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    # Extract data\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # Detection classes and boxes\n",
    "    detection_classes = detections['detection_classes'].astype(np.int64)\n",
    "    detection_boxes = detections['detection_boxes']\n",
    "\n",
    "    return detection_boxes, detection_classes\n",
    "\n",
    "# Example usage\n",
    "image_np = cv2.imread('path_to_your_image.jpg')\n",
    "boxes, classes = detect_objects(image_np, model)\n",
    "\n",
    "# Draw bounding boxes (example for visualization)\n",
    "for box in boxes:\n",
    "    y_min, x_min, y_max, x_max = box\n",
    "    start_point = (int(x_min * image_np.shape[1]), int(y_min * image_np.shape[0]))\n",
    "    end_point = (int(x_max * image_np.shape[1]), int(y_max * image_np.shape[0]))\n",
    "    cv2.rectangle(image_np, start_point, end_point, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Object Detection', image_np)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f375a-d009-4e82-956f-166e45e73d16",
   "metadata": {},
   "source": [
    "### 4. Improving Accuracy with Non-Max Suppression\n",
    "- Non-Max Suppression (NMS) is used to eliminate redundant overlapping bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c706fe5-8308-49ca-8c7e-bd2a0d8f3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, threshold):\n",
    "    assert len(boxes) == len(scores)\n",
    "    # Initialize an empty list for selected boxes\n",
    "    selected_boxes = []\n",
    "\n",
    "    # Sort the boxes by scores in descending order\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    while len(sorted_indices) > 0:\n",
    "        # Select the box with the highest score\n",
    "        selected_box_index = sorted_indices[0]\n",
    "        selected_boxes.append(boxes[selected_box_index])\n",
    "\n",
    "        # Compute IoU of the selected box with the rest\n",
    "        ious = np.array([iou(boxes[selected_box_index], box) for box in boxes[sorted_indices[1:]]])\n",
    "\n",
    "        # Remove indices of boxes with IoU greater than the threshold\n",
    "        sorted_indices = np.delete(sorted_indices, np.where(ious > threshold)[0] + 1)\n",
    "        sorted_indices = np.delete(sorted_indices, 0)\n",
    "\n",
    "    return np.array(selected_boxes)\n",
    "\n",
    "# You'll need to implement the 'iou' function to calculate Intersection over Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed271c-9538-4ada-871f-9a36c5fbf0e6",
   "metadata": {},
   "source": [
    "### 5. Intersection Over Union (IoU)\n",
    "- IoU is a measure to evaluate how much two bounding boxes overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1d061-2913-4470-877a-46f72f4274ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    # Calculate intersection area\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate union area\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    return intersection_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903844c-78b0-45fd-a3a0-b2df161506aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
